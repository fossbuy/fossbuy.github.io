{"title":"Can Language Models Learn to Listen?","uid":"bddf7a9978020ca2f84e02fda44f2bc4","slug":"Can-Language-Models-Learn-to-Listen","date":"2023-08-30T06:57:26.000Z","updated":"2023-08-30T07:04:07.215Z","comments":true,"path":"api/articles/Can-Language-Models-Learn-to-Listen.json","keywords":"ai,aigc,llm,web3,foss","cover":"/static/img/listen-llm-cover.png","content":"<p>Given a video of a listener and speaker pair, we extract text corresponding to the spoken words of the speaker.</p>\n<p>Demo: <a href=\"https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/\">https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/</a></p>\n<p>Paper: <a href=\"https://arxiv.org/abs/2308.10897\">https://arxiv.org/abs/2308.10897</a></p>\n<p>GitHub: <a href=\"https://github.com/sanjayss34/lm-listener\">https://github.com/sanjayss34/lm-listener</a></p>\n<p>License: Unknown but src is available online</p>\n<video width=\"480\" height=\"320\" controls=\"controls\">\n  <source src=\"https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/videos/teaser.mp4\" type=\"video/mp4\">\n</video>\n\n\n<p>Let the large language model understand human speech and make appropriate facial expressions and movements.</p>\n<p>To put it simply, when you chat with a chatbot, it can make corresponding smiles, frowns, etc. according to what you say, making the conversation more natural and real.</p>\n<p>working principle:</p>\n<p>This project proposes a framework for generating appropriate facial responses based on a speaker’s words. It uses a series of facial gestures of the listener, quantized by VQ-VAE, and feeds these gestures as additional language markers into a large transformer-based language model. The generated listener actions are fluent and reflect language semantics.</p>\n<p>For example, if the speaker said something happy, the model would make the virtual audience laugh; if the speaker said something uncomfortable, the model would make the virtual audience frown.</p>\n<p>The advantage of this is that the generated facial movements are not only natural, but also accurately reflect the speaker’s intentions and emotions, making the chatbot more like a real listener.</p>\n","text":"Given a video of a listener and speaker pair, we extract text corresponding to t...","link":"","photos":[],"count_time":{"symbolsCount":"1.4k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":2,"path":"api/categories/AIGC.json"}],"tags":[{"name":"Vision","slug":"Vision","count":2,"path":"api/tags/Vision.json"}],"toc":"","author":{"name":"FossBuy","slug":"blog-author","avatar":"static/img/logo.png","link":"/","description":"We help you discover Interesting AIGC & Web3 opensource projects, and tutorials how to build, deploy and appy them. Everything you need about FOSS AIGC and Web3 are here!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"mapped":true,"hidden":false,"prev_post":{"title":"A Survey on LLM-based Autonomous Agents","uid":"fd724a585030eaa1a6204c33e83516d8","slug":"A-Survey-on-LLM-based-Autonomous-Agents","date":"2023-08-30T07:12:38.000Z","updated":"2023-08-30T07:18:54.465Z","comments":true,"path":"api/articles/A-Survey-on-LLM-based-Autonomous-Agents.json","keywords":"ai,aigc,llm,web3,foss","cover":"/static/img/ai-agent-survey-cover.png","text":"Autonomous artificial intelligence (AI) agents are designed to accomplish specif...","link":"","photos":[],"count_time":{"symbolsCount":"1.3k","symbolsTime":"1 mins."},"categories":[{"name":"Agent","slug":"Agent","count":1,"path":"api/categories/Agent.json"}],"tags":[{"name":"Survey","slug":"Survey","count":1,"path":"api/tags/Survey.json"}],"author":{"name":"FossBuy","slug":"blog-author","avatar":"static/img/logo.png","link":"/","description":"We help you discover Interesting AIGC & Web3 opensource projects, and tutorials how to build, deploy and appy them. Everything you need about FOSS AIGC and Web3 are here!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}},"feature":true},"next_post":{"title":"3D Gaussian Splatting for Real-Time Radiance Field Rendering","uid":"1337ac1ac6dc10acd3fd4360edfba2de","slug":"3D-Gaussian-Splatting","date":"2023-08-29T14:13:51.000Z","updated":"2023-08-29T14:57:00.730Z","comments":true,"path":"api/articles/3D-Gaussian-Splatting.json","keywords":"ai,aigc,llm,web3,foss","cover":"/static/img/3D_Gaussian_Splatting_bicycle.png","text":"3D Gaussian Splatting: Only a set of photos or a video is needed to quickly gene...","link":"","photos":[],"count_time":{"symbolsCount":"1.2k","symbolsTime":"1 mins."},"categories":[{"name":"AIGC","slug":"AIGC","count":2,"path":"api/categories/AIGC.json"}],"tags":[{"name":"Vision","slug":"Vision","count":2,"path":"api/tags/Vision.json"}],"author":{"name":"FossBuy","slug":"blog-author","avatar":"static/img/logo.png","link":"/","description":"We help you discover Interesting AIGC & Web3 opensource projects, and tutorials how to build, deploy and appy them. Everything you need about FOSS AIGC and Web3 are here!","socials":{"github":"","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{}}}}}