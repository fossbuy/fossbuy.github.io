[{"id":"d2e4f1e29db6002c802fe0d486725631","title":"Whisper: a general-purpose speech recognition model","content":"Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multitasking model that can perform multilingual speech recognition, speech translation, and language identification.\nGitHub: https://github.com/openai/whisperPaper: https://arxiv.org/abs/2212.04356Model: https://huggingface.co/openai/whisper-large-v2\nLicense: Apache-2.0 (Model), MIT (Code)\n\nA Transformer sequence-to-sequence model is trained on various speech processing tasks, including multilingual speech recognition, speech translation, spoken language identification, and voice activity detection. These tasks are jointly represented as a sequence of tokens to be predicted by the decoder, allowing a single model to replace many stages of a traditional speech-processing pipeline. The multitask training format uses a set of special tokens that serve as task specifiers or classification targets.\n\n\n\nSize\nParameters\nEnglish-only model\nMultilingual model\nRequired VRAM\nRelative speed\n\n\n\ntiny\n39 M\ntiny.en\ntiny\n~1 GB\n~32x\n\n\nbase\n74 M\nbase.en\nbase\n~1 GB\n~16x\n\n\nsmall\n244 M\nsmall.en\nsmall\n~2 GB\n~6x\n\n\nmedium\n769 M\nmedium.en\nmedium\n~5 GB\n~2x\n\n\nlarge\n1550 M\nN&#x2F;A\nlarge\n~10 GB\n1x\n\n\n","slug":"Whisper-a-general-purpose-speech-recognition-model","date":"2023-09-23T08:24:33.000Z","categories_index":"Voice","tags_index":"Model","author_index":"FossBuy"},{"id":"18f87fc7373e0b9419263285cbc7cc8c","title":"Awesome Chinese LLM","content":"LLM for Chinese.\nGitHub: https://github.com/HqWu-HITCS/Awesome-Chinese-LLM\n","slug":"Awesome-Chinese-LLM","date":"2023-09-18T05:33:31.000Z","categories_index":"LLM","tags_index":"Model","author_index":"FossBuy"},{"id":"d2d2f577326238db898bd639a8dadfb3","title":"Scikit-LLM: Sklearn Meets Large Language Models","content":"Seamlessly integrate powerful language models like ChatGPT into the scikit-learn ecosystem for enhanced text analysis tasks.\nGitHub: https://github.com/iryna-kondr/scikit-llm\nIt aims to provide a convenient interface for leveraging LLMs in various machine learning pipelines, particularly those involving text data.\nHere‚Äôs what you can do with Scikit-LLM:\nüîπZero-Shot Text Classification:\nIt offers a ZeroShotGPTClassifier that allows text classification without re-training the model. The classifier works with descriptive labels.\nüî∏Few-Shot Text Classification\nThe FewShotGPTClassifier allows for few-shot classification, where training samples are added to the prompt and passed to the model.\nüîπDynamic Few-Shot Text Classification:\nThe DynamicFewShotGPTClassifier dynamically selects samples per class to include in the prompt, allowing the classifier to scale to larger datasets.\nüî∏Text Classification with Google PaLM 2:\nIt supports PaLM-based models like ZeroShotPaLMClassifier, PaLMClassifier, and PaLM for various text classification tasks.\nüîπText Vectorization:\nThe GPTVectorizer can be used for data preprocessing to embed text into fixed-dimensional vectors.\nüî∏LLM Fine-Tuning:\nIt supports fine-tuning scenarios for text classification and text-to-text tasks.\nüîπText Summarization:\nThe GPTSummarizer can be used as a stand-alone estimator or as a preprocessor for text summarization.\nüî∏Text Translation:\nThe GPTTranslator allows translating text into different languages.\nI have linked the official GitHub repo in next tweet!\nIf you liked this content &amp; are interested in:\n\nPython üêç\nML&#x2F;MLOps üõ†\nCV&#x2F;NLP üó£\nLLMs üß†\n\n","slug":"Scikit-LLM-Sklearn-Meets-Large-Language-Models","date":"2023-09-08T08:20:40.000Z","categories_index":"LLM","tags_index":"Framework","author_index":"FossBuy"},{"id":"3f4934f37dde3d3f22b6efc99e3a5a34","title":"DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models","content":"Large language models (LLMs) are prone to hallucinations, DoLa propose a simple decoding strategy for reducing hallucinations with pretrained LLMs that does not require conditioning on retrieved external knowledge nor additional fine-tuning.\npaper: https://arxiv.org/abs/2309.03883\nDoLa consistently improves the truthfulness across multiple choices tasks and open-ended generation tasks, for example improving the performance of LLaMA family models on TruthfulQA by 12-17% absolute points, demonstrating its potential in making LLMs reliably generate truthful facts.\n","slug":"DoLa-Decoding-by-Contrasting-Layers-Improves-Factuality-in-Large-Language-Models","date":"2023-09-08T08:15:00.000Z","categories_index":"LLM","tags_index":"Paper","author_index":"FossBuy"},{"id":"efb094830f507c6cf8fdd26e843c8146","title":"Tiny Llama only 1G!","content":"The TinyLlama project aims to pretrain a 1.1B Llama model on 3 trillion tokens.\nGitHub: https://github.com/jzhang38/TinyLlama\nThey adopted exactly the same architecture and tokenizer as Llama 2. This means TinyLlama can be plugged and played in many open-source projects built upon Llama. Besides, TinyLlama is compact with only 1.1B parameters. This compactness allows it to cater to a multitude of applications demanding a restricted computation and memory footprint.\nPotential UsecaseTiny but strong language models are useful for many applications. Here are some potential usecases:\n\nAssisting speculative decoding of larger models. (See this tutorial by Andrej Karpathy)\nDeployment on edge devices with restricted memory and computational capacities, for functionalities like real-time machine translation without an internet connection (the 4bit-quantized TinyLlama-1.1B‚Äôs weight only takes up 550MB RAM).\nEnabling real-time dialogue generation in video games.\n\n","slug":"Tiny-Llama-only-1B","date":"2023-09-06T04:25:33.000Z","categories_index":"LLM","tags_index":"Model","author_index":"FossBuy"},{"id":"97e046036a6582db224e4d185d74ad48","title":"The cheapest chatbot solution SymeChat","content":"SymeChat takes advantage of Llama2 7B‚Äôs powerful natural language understanding and generation abilities to enable chatbots, virtual assistants and other AI applications with human-level conversational skills. By leveraging Llama2 7B in the cloud, SymeChat eliminates the need for customers to purchase expensive GPU hardware or deal with the complexities of maintaining and updating neural networks themselves. Customers will pay based on monthly usage without any upfront infrastructure costs.\nNews: https://syme.dev/articles/news/0GitLab: https://gitlab.com/SymeCloud/syme-chatAmazon AWS: https://aws.amazon.com/marketplace/pp/prodview-gzehsbllm3q3o\nFor SymeChat 7B. The software license is currently $4.99&#x2F;month, unlimited instances, and AWS cloud cost depends on your usage. It‚Äôs around $0.083&#x2F;hour if you don‚Äôt have AWS saving plan. The cost will be down to around $0.02~$0.04&#x2F;hour if your AWS saving plan is available.\n\n","slug":"The-cheapest-chatbot-solution-SymeChat","date":"2023-09-01T16:47:38.000Z","categories_index":"LLM","tags_index":"Llama2","author_index":"FossBuy"},{"id":"fd724a585030eaa1a6204c33e83516d8","title":"A Survey on LLM-based Autonomous Agents","content":"Autonomous artificial intelligence (AI) agents are designed to accomplish specific objectives by self-guided instructions, automatic memorization, planning, and action. With the advent and prospering of large language models (LLMs), there is an expanding frontier in using LLMs as core controllers for these autonomous entities.\nPaper: https://arxiv.org/abs/2308.11432\nGitHub: https://github.com/Paitesanshi/LLM-Agent-Survey\n\nHowever, a unified view that ties together the diverse studies in this field has been lacking. This repository houses a comprehensive and systematic survey that fills this gap, focusing on LLM-based autonomous AI agents in their construction, applications, and evaluation strategies.\nIn particular, we explore the essential components of an AI agent, including a profile module, a memory module, a planning module, and an action module. We further investigate the potential applications in natural and social sciences and introduce methods to evaluate their effectiveness. Challenges and future directions of this field are also discussed.\nThe paper and repository aim to serve as a resource for researchers and practitioners alike, providing insights, related references, and continuous updates on this exciting and rapidly evolving field.\n","slug":"A-Survey-on-LLM-based-Autonomous-Agents","date":"2023-08-30T07:12:38.000Z","categories_index":"Agent","tags_index":"Survey","author_index":"FossBuy"},{"id":"bddf7a9978020ca2f84e02fda44f2bc4","title":"Can Language Models Learn to Listen?","content":"Given a video of a listener and speaker pair, we extract text corresponding to the spoken words of the speaker.\nDemo: https://people.eecs.berkeley.edu/~evonne_ng/projects/text2listen/\nPaper: https://arxiv.org/abs/2308.10897\nGitHub: https://github.com/sanjayss34/lm-listener\nLicense: Unknown but src is available online\n\n  \n\n\n\nLet the large language model understand human speech and make appropriate facial expressions and movements.\nTo put it simply, when you chat with a chatbot, it can make corresponding smiles, frowns, etc. according to what you say, making the conversation more natural and real.\nworking principle:\nThis project proposes a framework for generating appropriate facial responses based on a speaker‚Äôs words. It uses a series of facial gestures of the listener, quantized by VQ-VAE, and feeds these gestures as additional language markers into a large transformer-based language model. The generated listener actions are fluent and reflect language semantics.\nFor example, if the speaker said something happy, the model would make the virtual audience laugh; if the speaker said something uncomfortable, the model would make the virtual audience frown.\nThe advantage of this is that the generated facial movements are not only natural, but also accurately reflect the speaker‚Äôs intentions and emotions, making the chatbot more like a real listener.\n","slug":"Can-Language-Models-Learn-to-Listen","date":"2023-08-30T06:57:26.000Z","categories_index":"AIGC","tags_index":"Vision","author_index":"FossBuy"},{"id":"1337ac1ac6dc10acd3fd4360edfba2de","title":"3D Gaussian Splatting for Real-Time Radiance Field Rendering","content":"3D Gaussian Splatting: Only a set of photos or a video is needed to quickly generate a 3D model.\nSite: https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/GitHub: https://github.com/graphdeco-inria/gaussian-splattingLicense: Gaussian-Splatting License (free for non-commercial, research and evaluation)\n\n\n  \n\n\n\n\nAnd this 3D model not only looks real, but also easier and faster to make than other methods.\nIt uses a mathematical tool called ‚Äú3D Gaussian function‚Äù to represent this 3D model, and finds a faster algorithm to render (i.e. generate) the 3D model. #gaussiansplatting\nEasy to understand explanation:\nImagine you have a bunch of photos or videos and you want to see the scenes from a whole new perspective. 3D Gaussian Splatting is an advanced tool that allows you to do just that. It ‚Äúrecreates‚Äù these scenes in an exceptionally fast and high-quality manner, allowing you to view them from any angle as if you were actually standing there.\nThe ‚Äúbrain‚Äù of the tool uses a mathematical model called a 3D Gaussian that describes every detail of the scene with great precision. Even cooler, the tool also displays these new angles of the scene in real-time, meaning you don‚Äôt have to wait long to see the results.\n","slug":"3D-Gaussian-Splatting","date":"2023-08-29T14:13:51.000Z","categories_index":"AIGC","tags_index":"Vision","author_index":"FossBuy"},{"id":"65f60956c3207b3b6622abbe02a00143","title":"WizardLM: Empowering Large Pre-Trained Language Models to Follow Complex Instructions","content":"WizardLM team brings their three new models recently: WizardCoder, WizardLM, WizardMath.\nGitHub: https://github.com/nlpxucan/WizardLMLicense: Apache-2.0\nThe coding evaluation benchmark looks really amazing:\n\n\n","slug":"WizardLM","date":"2023-08-21T09:56:32.000Z","categories_index":"LLM","tags_index":"Model","author_index":"FossBuy"},{"id":"b9663f58f18133b35bfe243f3e916a80","title":"Hello World","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub.\nQuick StartCreate a new post$ hexo new &quot;My New Post&quot;\n\nMore info: Writing\nRun server$ hexo server\n\nMore info: Server\nGenerate static files$ hexo generate\n\nMore info: Generating\nDeploy to remote sites$ hexo deploy\n\nMore info: Deployment\n","slug":"hello-world","date":"2023-08-18T16:02:29.550Z","categories_index":"","tags_index":"","author_index":"FossBuy"}]